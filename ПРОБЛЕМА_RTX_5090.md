# ‚ö†Ô∏è –í–∞–∂–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞: RTX 5090 –∏ PyTorch

## –°—É—Ç—å –ø—Ä–æ–±–ª–µ–º—ã

**RTX 5090 –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è PyTorch** –∏–∑-–∑–∞ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Blackwell (compute capability 12.0).

### –û—à–∏–±–∫–∞, –∫–æ—Ç–æ—Ä—É—é –≤—ã –º–æ–≥–ª–∏ –≤–∏–¥–µ—Ç—å:
```
RuntimeError: CUDA error: no kernel image is available for execution on the device
RuntimeError: not enough memory: you tried to allocate 3758096384 bytes
```

## –ü–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç?

1. **RTX 5090** - –æ—á–µ–Ω—å –Ω–æ–≤–∞—è –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞ (–∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞ —è–Ω–≤–∞—Ä—å 2025)
2. **PyTorch** –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ compute capabilities –¥–æ **sm_90** (Ada Lovelace, RTX 40xx)
3. **RTX 5090** –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **sm_120** (Blackwell), –∫–æ—Ç–æ—Ä–∞—è –µ—â–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è

## –†–µ—à–µ–Ω–∏—è

### ‚úÖ –†–µ—à–µ–Ω–∏–µ 1: CPU —Ä–µ–∂–∏–º (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å–µ–π—á–∞—Å)

–Ø –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª –∫–æ–¥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ GPU –∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ CPU –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.

**–ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:**
```cmd
set HF_TOKEN=–≤–∞—à_—Ç–æ–∫–µ–Ω
monocle.exe --binary "–ø—É—Ç—å\–∫\—Ñ–∞–π–ª—É.exe" --find "authentication code"
```

**–ü–ª—é—Å—ã:**
- –†–∞–±–æ—Ç–∞–µ—Ç –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å
- –ù–µ —Ç—Ä–µ–±—É–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π PyTorch

**–ú–∏–Ω—É—Å—ã:**
- ‚ö†Ô∏è **–û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ** (–≤ 10-50 —Ä–∞–∑ –º–µ–¥–ª–µ–Ω–Ω–µ–µ GPU)
- ‚ö†Ô∏è **–¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ RAM** (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 32GB+)
- –ú–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –Ω–∞ –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π —Ñ—É–Ω–∫—Ü–∏–∏

### üîÑ –†–µ—à–µ–Ω–∏–µ 2: –î–æ–∂–¥–∞—Ç—å—Å—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ PyTorch (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

PyTorch –æ–±—ã—á–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫—É –Ω–æ–≤—ã—Ö GPU –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –≤ —Ç–µ—á–µ–Ω–∏–µ 2-6 –º–µ—Å—è—Ü–µ–≤ –ø–æ—Å–ª–µ —Ä–µ–ª–∏–∑–∞.

**–û—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:**
- PyTorch GitHub: https://github.com/pytorch/pytorch/issues
- PyTorch –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç: https://pytorch.org/get-started/locally/

**–ö–æ–≥–¥–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–æ—è–≤–∏—Ç—Å—è, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:**
```cmd
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

### üîß –†–µ—à–µ–Ω–∏–µ 3: –ö–æ–º–ø–∏–ª—è—Ü–∏—è PyTorch –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤

**–¢–æ–ª—å–∫–æ –¥–ª—è –æ–ø—ã—Ç–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π!**

–ú–æ–∂–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π sm_120:

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å PyTorch
git clone --recursive https://github.com/pytorch/pytorch
cd pytorch

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
set TORCH_CUDA_ARCH_LIST=12.0
set CMAKE_CUDA_ARCHITECTURES=120

# –ö–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å (–∑–∞–π–º—ë—Ç 2-4 —á–∞—Å–∞)
python setup.py develop
```

‚ö†Ô∏è **–í–Ω–∏–º–∞–Ω–∏–µ:** –≠—Ç–æ —Å–ª–æ–∂–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, —Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –º–æ–∂–µ—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞—Ç—å.

## –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ: –î—Ä—É–≥–∞—è GPU –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –¥—Ä—É–≥–æ–π GPU (RTX 30xx/40xx, Tesla, –∏ —Ç.–¥.), –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –µ—ë –¥–ª—è Monocle –¥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ RTX 5090.

## –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ —Ç–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è PyTorch –≤–∞—à—É GPU:

```cmd
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'); print('Compute capability:', torch.cuda.get_device_capability(0) if torch.cuda.is_available() else 'N/A')"
```

–ï—Å–ª–∏ —É–≤–∏–¥–∏—Ç–µ compute capability `(12, 0)` –∏ –Ω–µ—Ç –æ—à–∏–±–æ–∫ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏:
```cmd
python -c "import torch; x = torch.rand(5, 3).cuda(); print(x * 2)"
```

–ó–Ω–∞—á–∏—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–æ—è–≤–∏–ª–∞—Å—å!

## –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã

‚úÖ **–î—Ä–∞–π–≤–µ—Ä–∞ NVIDIA:** –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã (CUDA 13.0)  
‚úÖ **RTX 5090:** –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ (31.84 GB –ø–∞–º—è—Ç–∏)  
‚ö†Ô∏è **PyTorch:** –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –Ω–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç sm_120  
‚úÖ **Monocle:** –û–±–Ω–æ–≤–ª—ë–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ CPU —Ä–µ–∂–∏–º–µ  

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

**–î–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã:**
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CPU —Ä–µ–∂–∏–º –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö —Ç–µ—Å—Ç–æ–≤ (1-2 —Ñ—É–Ω–∫—Ü–∏–∏)
2. –î–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–æ–ª—å—à–∏—Ö –±–∏–Ω–∞—Ä–Ω–∏–∫–æ–≤ –¥–æ–∂–¥–∏—Ç–µ—Å—å –ø–æ–¥–¥–µ—Ä–∂–∫–∏ RTX 5090 –≤ PyTorch
3. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±–ª–∞—á–Ω—ã–µ GPU —Å–µ—Ä–≤–∏—Å—ã (Google Colab, AWS, Azure) –≤—Ä–µ–º–µ–Ω–Ω–æ

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **Compute Capability —Ç–∞–±–ª–∏—Ü–∞:** https://developer.nvidia.com/cuda-gpus
- **PyTorch CUDA support:** https://pytorch.org/docs/stable/notes/cuda.html
- **–û–±—Å—É–∂–¥–µ–Ω–∏–µ RTX 50xx:** https://github.com/pytorch/pytorch/issues (–ø–æ–∏—Å–∫ "RTX 5090" –∏–ª–∏ "Blackwell")
